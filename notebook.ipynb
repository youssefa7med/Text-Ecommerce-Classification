{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TF-IDF?\n",
    "\n",
    "- TF stands for **Term Frequency** and denotes the ratio of  number of times a particular word appeared in a Document to total number of words in the document.\n",
    "          \n",
    "         Term Frequency(TF) = [number of times word appeared / total no of words in a document]\n",
    " \n",
    "- Term Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\n",
    "\n",
    "\n",
    "- IDF stands for **Inverse Document Frequency** and denotes the log of ratio of total number of documents/datapoints in the whole dataset to the number of documents that contains the particular word.\n",
    "\n",
    "         Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)]\n",
    "        \n",
    "- In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0. \n",
    "\n",
    "\n",
    "- Finally:\n",
    "         \n",
    "         TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TF-IDF?\n",
    "\n",
    "TF-IDF ببساطة هو طريقة بنستخدمها عشان نقيس أهمية كلمة معينة في نص معين بالنسبة لبقية الكلمات في مجموعة نصوص.\n",
    "\n",
    "خلينا نبسط الموضوع أكتر:\n",
    "\n",
    "- **TF** أو \"تكرار الكلمة\" هو نسبة عدد مرات ظهور كلمة معينة في نص واحد لعدد الكلمات الكلي في النص ده. يعني لو كلمة ظهرت 5 مرات في نص فيه 100 كلمة، فالنسبة هتكون 5/100.\n",
    "  \n",
    "- **IDF** أو \"عكس تكرار المستند\" هو اللي بيقولنا إذا كانت الكلمة دي شائعة في كل النصوص ولا لأ. لو كلمة ظهرت في كل النصوص، معناها إنها مش مهمة أوي لأن الكل بيستخدمها. لكن لو ظهرت في عدد قليل من النصوص، هتكون أهم.\n",
    "\n",
    "- وأخيراً: **TF-IDF** بيجمع بين الاتنين. بنضرب **TF** في **IDF**، عشان نطلع قيمة توضح لنا مدى أهمية الكلمة دي في النص بتاعنا.\n",
    "\n",
    "يعني لو الكلمة بتتكرر كتير في نص معين، لكن مش موجودة في كل النصوص، هتكون مهمة. أما لو الكلمة دي بتتكرر في كل النصوص، هتكون قيمتها أقل.\n",
    "\n",
    "ببساطة، هي طريقة بنستخدمها عشان نعرف إيه الكلمات المهمة في النص ده مقارنة ببقية النصوص.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Condition**                                         | **TF** (Word Frequency in the Document) | **IDF** (Word Frequency in Other Documents) | **TF-IDF** (Word Importance)     | **Word Importance**             |\n",
    "|-------------------------------------------------------|----------------------------------------|--------------------------------------------|----------------------------------|---------------------------------|\n",
    "| The word appears frequently in one document           | High                                   | Low                                       | Low                              | Not very important              |\n",
    "| The word appears infrequently in one document         | Low                                    | High                                      | Medium to High                   | Important                       |\n",
    "| The word appears frequently in one document and many others | High                                   | Low                                       | Low                              | Not important                   |\n",
    "| The word appears infrequently in one document and rarely in others | Low                                    | High                                      | High                             | Very important                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "transformed  = v.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24266547, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24266547, 0.        , 0.        ,\n",
       "        0.40286636, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24266547, 0.11527033, 0.24266547, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.72799642, 0.        , 0.        ,\n",
       "        0.24266547, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.5680354 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5680354 ,\n",
       "        0.        , 0.26982671, 0.        , 0.        , 0.        ,\n",
       "        0.30652086, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30652086, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26982671, 0.        , 0.        , 0.5680354 ,\n",
       "        0.30652086, 0.        , 0.        , 0.        , 0.5680354 ,\n",
       "        0.        , 0.30652086, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.5680354 , 0.        , 0.        ,\n",
       "        0.        , 0.26982671, 0.        , 0.        , 0.        ,\n",
       "        0.30652086, 0.5680354 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30652086, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26982671, 0.        , 0.5680354 , 0.        ,\n",
       "        0.30652086, 0.        , 0.        , 0.5680354 , 0.        ,\n",
       "        0.        , 0.30652086, 0.        ],\n",
       "       [0.        , 0.        , 0.49391316, 0.        , 0.26652333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.49391316,\n",
       "        0.        , 0.49391316, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23461736, 0.        , 0.        , 0.        ,\n",
       "        0.26652333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.26652333, 0.        ],\n",
       "       [0.        , 0.33794257, 0.        , 0.33794257, 0.        ,\n",
       "        0.        , 0.33794257, 0.        , 0.33794257, 0.        ,\n",
       "        0.56104271, 0.        , 0.        , 0.33794257, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33794257]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['already', 'am', 'amazon', 'and', 'announcing', 'apple', 'are',\n",
       "       'ate', 'biryani', 'dot', 'eating', 'eco', 'google', 'grapes',\n",
       "       'iphone', 'ironman', 'is', 'loki', 'microsoft', 'model', 'new',\n",
       "       'pixel', 'pizza', 'surface', 'tesla', 'thor', 'tomorrow', 'you'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
     ]
    }
   ],
   "source": [
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thor : 2.386294361119891\n",
      "eating : 1.9808292530117262\n",
      "pizza : 2.386294361119891\n",
      "loki : 2.386294361119891\n",
      "is : 1.1335313926245225\n",
      "ironman : 2.386294361119891\n",
      "ate : 2.386294361119891\n",
      "already : 2.386294361119891\n",
      "apple : 2.386294361119891\n",
      "announcing : 1.2876820724517808\n",
      "new : 1.2876820724517808\n",
      "iphone : 2.386294361119891\n",
      "tomorrow : 1.2876820724517808\n",
      "tesla : 2.386294361119891\n",
      "model : 2.386294361119891\n",
      "google : 2.386294361119891\n",
      "pixel : 2.386294361119891\n",
      "microsoft : 2.386294361119891\n",
      "surface : 2.386294361119891\n",
      "amazon : 2.386294361119891\n",
      "eco : 2.386294361119891\n",
      "dot : 2.386294361119891\n",
      "am : 2.386294361119891\n",
      "biryani : 2.386294361119891\n",
      "and : 2.386294361119891\n",
      "you : 2.386294361119891\n",
      "are : 2.386294361119891\n",
      "grapes : 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "for word in v.vocabulary_:\n",
    "    index = v.vocabulary_.get(word)\n",
    "    idf_score = v.idf_[index]\n",
    "    print(f'{word} : {idf_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24266547 0.         0.         0.         0.         0.\n",
      " 0.         0.24266547 0.         0.         0.40286636 0.\n",
      " 0.         0.         0.         0.24266547 0.11527033 0.24266547\n",
      " 0.         0.         0.         0.         0.72799642 0.\n",
      " 0.         0.24266547 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(transformed.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
